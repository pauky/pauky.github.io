---
title: 《机器学习实战》（笔记）— k-近邻算法
date: 2018/02/20 10:39:34
last_updated: 2018/02/20 10:39:38
online_time: 2018/02/20 10:39:38
description: k-近邻算法
categories:
  - tech
tags:
  - ml
---

# k-近邻算法
## 学习内容
- 1.理解k-近邻算法的原理
- 2.k-近邻算法的实现

## 我的理解
- k-近邻算法一定作为分类识别，是一种较为简单直接的算法。将待识别的数据特征与数据集里的特征进行比较，通过一定规则算出与所有样本的距离，选取k个最相近的数据（通常k不大于20），k个最相似数据中出现次数最多的分类，就作为待识别数据的分类。
    虽然这种算法精度高、对异常值不敏感，然而也存在计算复杂度高的缺点。
    
- 下面作一个k-近邻算法的简单示例：
    创建一个含有4个向量、分别属于AB两类的数据集：
    ```python
    def createDataSet():
        group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])
        labels = ['A','A','B','B']
        return group, labels
    ```
    kNN分类算法实现：
    ```python
    def classify0(inX, dataSet, labels, k):
        # 待识别数据与数据集每个样本的距离计算
        # 距离的计算使用欧氏距离公式
        dataSetSize = dataSet.shape[0]
        diffMat = tile(inX, (dataSetSize,1)) - dataSet
        sqDiffMat = diffMat**2
        sqDistances = sqDiffMat.sum(axis=1)
        distances = sqDistances**0.5
        sortedDistIndicies = distances.argsort()     
        classCount={}  
        # 获取距离最小的k个点
        for i in range(k):
            voteIlabel = labels[sortedDistIndicies[i]]
            classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1
        # 使用operator模块的itemgetter方法，排序并返回发生频率最高的元素标签
        sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)
        return sortedClassCount[0][0]

    ```
    运行效果：
    ```
    >>> import kNN
    >>> kNN.classify0([0,0], group, labels, 3)
    'B'
    ```
    完整代码实现可查看：[kNN](https://github.com/pauky/machine_learning_in_action/blob/master/kNN.py)，或者直接阅读[《机器学习实战》](https://www.manning.com/books/machine-learning-in-action)第2章内容。
    
## 意义
理解并实现了kNN分类算法，掌握了这一简单直接的机器学习算法原理。
