---
title: 开发总结—SEO篇（sitemap与robots.txt）
date: 2015/12/10 12:20:29
last_updated: 2015/12/15 12:39:42
online_time: 2015/12/10 12:20:38
description: 生成网页地图sitemap与robots.txt
categories:
  - tech
tags:
  - seo
---

![网络爬虫](https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcRPJWrvh3u01H4EDvUQt2o9dJgAdBGEWvZtL3-lO5elU0VdB4VN)
今早做了一些SEO优化，增加了sitemap与robots.txt。
> 有关sitemap： 

sitemap，也称网页地图，是让搜索引擎知道你的网站结构是怎样的，主要是暴露链接让搜索引擎来抓取你的网站。[详细了解请点击此处](http://baike.baidu.com/view/1072062.htm)

> 有关robots.txt: 

robots.txt是告诉搜索引擎你的网站哪些东西可以抓取，哪些不可以。
[详细了解请点击此处](https://zh.wikipedia.org/wiki/Robots.txt)

## sitemap
本站使用的是node.js + express，所以我采用了[sitemap](https://www.npmjs.com/package/sitemap)这个模块来生成网站地图。下面展示下我的做法：

1.首先是创建网站首页、技术博客、生活杂记的索引；
```javascript
var sm = require('sitemap');
var sitemap = sm.createSitemap({
    hostname: config.portalUrl,
    cacheTime: 600000,
    urls: [
        {url: config.portalUrl, changefreq: 'always', priority: 1, lastmod: moment().format('YYYY-MM-DD')},
        {url: config.portalUrl + '/tech', changefreq: 'daily', priority: 0.8, lastmod: moment().format('YYYY-MM-DD')},
        {url: config.portalUrl + '/life', changefreq: 'daily', priority: 0.8, lastmod: moment().format('YYYY-MM-DD')}
    ]
});
```

2.查找文章及标签数据，加载索引；
```javascript
// 添加文章索引
_.each(results.getArticles, function (art) {
	sitemap.del({url: config.portalUrl + '/a/' + art.order}); // 删除重复
		sitemap.add({
		url: config.portalUrl + '/a/' + art.order + '.html',
		lastmod: moment(art.lastUpdateTime).format('YYYY-MM-DD'),
		changefreq: 'daily',
		priority: 0.5
	});
});
// 添加标签索引
_.each(results.getTags, function (tag) {
	sitemap.del({url: config.portalUrl + '/tag/' + tag.enName}); // 删除重复
	sitemap.add({
		url: config.portalUrl + '/tag/' + tag.enName,
		lastmod: moment().format('YYYY-MM-DD'),
		changefreq: 'daily',
		priority: 0.5
	});
});
res.header('Content-Type', 'application/xml');
res.send( sitemap.toString() ); // 返回网站地图文件
```

3.最后增加路由规则；
```javascript
'/sitemap.xml': siteMapController.createSiteMap,
```

这样就完成了本站网站地图的制作，[效果展示](http://yangrunwei.com/sitemap.xml)

## robots.txt
我也采用了比较简便的方式来生成robots.txt。
1.首页是在工程根目录（也可以自定义）创建robots.txt；
2.可以在线生成此文件，网上搜索下“robots.txt 在线生成”，会有一些在线工具提供。也可以采用手动编辑的方式，具体规则可查看[百度的描述](http://zhanzhang.baidu.com/college/courseinfo?id=267&page=12#h2_article_title28)；
3.添加路由规则
```javascript
'/robots.txt': siteMapController.createRobot
```
这样就完成了本站robots.txt的制作，[效果展示](http://yangrunwei.com/robots.txt)

## 写在最后
最后还要把sitemap.xml和robots.txt的链接地址提交给谷歌和百度等搜索引擎，这样爬虫才能尽快发现你的网站。





