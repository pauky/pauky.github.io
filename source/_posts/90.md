---
title: 动手学深度学习（笔记）- 卷积神经网络
date: 2018/02/18 10:29:45
last_updated: 2018/02/18 05:14:50
online_time: 2018/02/18 10:29:48
description: 卷积神经网络
categories:
  - tech
tags:
  - ml
---

# 卷积神经网络
## 学习内容
- 1.什么是卷积神经网络
- 2.为什么要使用卷积神经网络

## 我的理解
- 卷积神经网络除了包含普通神经网络的输入输出层、激励层、隐含层之外，还有两种特殊的结构：卷积计算层和池化层；
    卷积计算层：用于线性乘积 求和；
    了解卷积神经网络，首先要了解什么是卷积：
    对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做**内积**（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源；举个具体的例子。比如下图中，图中左边部分是原始输入数据，图中中间部分是滤波器filter，图中右边是输出的新的二维数据：
    ![Minion](http://img.blog.csdn.net/20160702215705128)
    中间滤波器filter与数据窗口做内积，其具体计算过程则是：4\*0 + 0\*0 + 0\*0 + 0\*0 + 0\*1 + 0\*1 + 0\*0 + 0\*1 + -4*2 = -8;
    池化层：取区域平均或最大；
    下面举个简单的池化例子：
    ![Minion](http://img.blog.csdn.net/20160703121026432)
    上图所展示的是取区域最大，即上图左边部分中 左上角2x2的矩阵中6最大，右上角2x2的矩阵中8最大，左下角2x2的矩阵中3最大，右下角2x2的矩阵中4最大，所以得到上图右边部分的结果：6 8 3 4;
    
- 卷积层的两个要点：**局部连接（Local Connection）**和**权值共享（Weight Sharing）**;
    局部连接和权值共享降低了参数量，使训练复杂度大大下降，并减轻了过拟合。同时权值共享还赋予了卷积网络对平移的容忍性;
    池化层的降采样输出参数量，并赋予了模型对轻度形变的容忍性，提高了模型的泛化能力;
    相比较其他深度、前馈神经网路，卷积神经网路需要考量的参数更少。
    
## 意义
了解了对图像识别更友好有效的卷积神经网络的基本组成结构和实现原理。

## 参考
[动手学深度学习-卷积神经网络](https://zh.gluon.ai/chapter_convolutional-neural-networks/cnn-scratch.html)
[通俗理解卷积神经网络](http://blog.csdn.net/v_july_v/article/details/51812459)
