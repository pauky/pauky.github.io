---
title: 修复爬虫抓取文章详情bug
date: 2015/12/15 10:44:55
last_updated: 2015/12/15 10:51:28
online_time: 2015/12/15 10:50:43
description: 修复了搜索引擎爬虫对行之足文章详情抓取报500错误的bug
categories:
  - tech
tags:
  - qianlizhixing
---

  平时偶尔在日志里发现Goglebot对于行之足文章详情抓取后返回500状态，因为当时文章数量只有几篇，而且版本发布比较频繁，自己访问这些页面也没有是正常的，在百度站长工具上也没发现啥抓取异常，所以就天真地以为爬虫抓取时刚好正在发布或者是google爬虫在国外的原因，从而导致这种500状态现象。
  
  然而随着在Google Search Console上看到越来越多的抓取异常，而且也基本上没有收录行之足的文章详情页面。这时便促使我不得不把这个问题揪出来。
  
  Google Search Console上有抓取方式这个功能，可以让爬虫主动来抓取某个链接。我便是用这个工具来debug的。
  
  一开始以为是页面加载了过多资源导致的，直到我把页面上所有资源甚至dom结构都去除时，都还是抓取异常。还有就是把这种链接规则转到其它页面（比如首页）却是可以抓取得到的。
  
  其实当时也是因为我这种做前端的惯性思维，出现问题时都往前端的方向去想。等到我看到后端接口时才突然醒悟，这个页面跟其它页面的区别就于多了个爬虫不加热度的分支，细看才发现爬虫的分支居然有个重要的函数名写错了，真是个十分低级的错误。无奈bug fix后终于抓取正常了。
  
### 这里也分享下我在node.js里判断爬虫的方法。
行之足使用的是[express-useragent](https://github.com/biggora/express-useragent)
```javascipt
var express = require('express');
var app = express();
var useragent = require('express-useragent');

app.use(useragent.express());
app.get('/', function(req, res){
    if(req.useragent.isBot){
		res.send('爬虫来咯');
	} else {
		res.send('正常用户');
	}
});
```

### 吐槽与总结
  鉴于出现这种低级的错误，我在这对我的粗心进行批评和记录，希望以后能以此为鉴，做事细心再细心。
  
  接下来我想吐槽百度的站长工具，居然抓取异常那里一直都没显示这些数据，明明爬虫过来时就500了，然而就这样一直被和谐起来，真是坑。不得不佩服人家google，收录快，信息更新迅速，这就是差距呀呀！！！
