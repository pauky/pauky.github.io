<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="杨润炜"><meta name="copyright" content="杨润炜"><title>Cwalker</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.2.0'
} </script><meta name="generator" content="Hexo 6.2.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">杨润炜</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">135</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">29</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">2</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Cwalker</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Cwalker</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/a/85.html">动手学深度学习（笔记）—监督学习之线性回归</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-02-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/ml/">ml</a></span><div class="content"><h1 id="监督学习—线性回归"><a href="#监督学习—线性回归" class="headerlink" title="监督学习—线性回归"></a>监督学习—线性回归</h1><h2 id="学习内容"><a href="#学习内容" class="headerlink" title="学习内容"></a>学习内容</h2><ul>
<li>1.NDArray和autograd处理数据和自动求导</li>
<li>2.线性回归-从0开始</li>
<li>3.线性回归-使用gluon</li>
</ul>
<h2 id="我的理解"><a href="#我的理解" class="headerlink" title="我的理解"></a>我的理解</h2><ul>
<li>矩阵运算是机器学习的核心基础之一，算法处理数据都是矩阵的运算、求导过程。NDArray提供了操作符、替换、截取等操作，进行对矩阵数据的存储和变换，autograd则提供了更新模型参数所需的自动求导功能。</li>
<li>模型训练流程：<br>  <strong>获取数据集</strong>：用线性函数加噪声的方式生产训练数据，噪声是为了模拟现实情况的数据，所以使用了能反应普遍规律的正态分布；<br>  <strong>定义模型</strong>：y  ̂    &#x3D;X w+b；<br>  <strong>确定损失函数</strong>：模型的方差：∑ i&#x3D;1 n (y  ̂     i −y i ) 2 ，这里方差的体现了实际数据与直线的欧氏距离之和，显然距离最小的时候，模型最能反映实际数据了；<br>  <strong>优化算法</strong>：采用梯度下降使损失最小化，首先是确定模型参数的初始值、梯度下降的学习率及训练迭代次数，然后以学习率为单位逐渐减小参数的偏导数，使平均损失值逐渐减小，迭代完成后，就可以得到此次训练的最优参数值和模型；查阅资料时发现还可以使用最小二乘法求解，利用导数为零时损失最小的原理，在参数的偏导公式中代入训练数据求出具体参数值；不过由于矩阵的逆计算量大而且存在数值不稳定的情况，所以迭代法（如：梯度下降）更适合实际训练。</li>
<li>gluon引入了一些抽象概念和更便捷的数据处理方法，有加载数据的data模块，模型层（如：线性模型的Dense），内置方差计算和梯度下降法运算。gluon使模型训练更快，实现起来更简洁。</li>
</ul>
<h2 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h2><p>理解机器学习最简单的线性模型原理及实现，了解gluon的一些基本用法和抽象概念。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zh.gluon.ai/">动手学深度学习</a><br><a target="_blank" rel="noopener" href="http://blog.csdn.net/suibianshen2012/article/details/51393733">最小二乘法与梯度下降</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/84.html">动手学深度学习（笔记）-机器学习简介</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-02-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/ml/">ml</a></span><div class="content"><h1 id="机器学习简介"><a href="#机器学习简介" class="headerlink" title="机器学习简介"></a>机器学习简介</h1><h2 id="笔记序言"><a href="#笔记序言" class="headerlink" title="笔记序言"></a>笔记序言</h2><p>接下来会有一波关于深度学习入门资源（<a target="_blank" rel="noopener" href="https://zh.gluon.ai/">动手学深度学习</a>）的笔记，建议有兴趣的朋友到其资源网站上查阅。</p>
<h2 id="学习的内容"><a href="#学习的内容" class="headerlink" title="学习的内容"></a>学习的内容</h2><ul>
<li>1.什么是机器学习、机器学习的流程</li>
<li>2.机器学习最简要素</li>
<li>3.了解监督学习</li>
<li>4.了解无监督学习</li>
<li>5.需要与环境交互的机器学习</li>
</ul>
<h2 id="我的理解"><a href="#我的理解" class="headerlink" title="我的理解"></a>我的理解</h2><ul>
<li><p>1.机器学习就是用&#x3D;&#x3D;数据&#x3D;&#x3D;来进行计算机编程的过程。通过选定的&#x3D;&#x3D;模型&#x3D;&#x3D;算法，并配置合适的&#x3D;&#x3D;参数&#x3D;&#x3D;，将大量数据输入迭代，达到预期效果。下图可以很好地展示了机器学习的流程：<br><img src="https://zh.gluon.ai/_images/ml-loop.png" alt="Minion"></p>
</li>
<li><p>2.四个要素：<br>  <strong>数据</strong>：量越多越好，而且要具备所要训练的各种维度信息，维度信息一般都需要人工标注；<br>  <strong>模型</strong>：分析统计数据维度信息的算法；<br>  <strong>损失函数</strong>：比较模型结果与真实结果好坏来衡量模型好坏的方法，包含用训练数据比较得出的训练误差和用测试数据比较得出的测试误差；<br>  <strong>优化算法</strong>：调整参数，逐渐最小化损失的方法。</p>
</li>
<li><p>3.<strong>监督学习</strong>：通过大量包含输入x和对应输出y的数据，估算条件概率P(y|x)，典型特点是每个输入都具有人工给定的目标值。<br>  几种监督学习：<br>  回归分析：输入单一或多个的连续或离散的变量，得到连续的结果；<br>  分类：能够得到预先规定好的结果类别，结果往往是所有分类都有一个判定概率，这里选定概率最大的作为最优解。比如文字识别（OCR）、色情识别；<br>  标注：预测所有可能的非互斥分类，可以为被标注对象的定义多个标签；<br>  搜索与排序：搜集有效的数据，并进行有效权重排序的过程；<br>  推荐系统：包含用户个性化定制的搜索与排序；<br>  序列学习：输入与输出都可能是任务长度的序列，而且需要处理各个输入之间可能存在的联系，如语音识别、机器翻译等。</p>
</li>
<li><p>4.<strong>无监督学习</strong>：没有为特定的输入给出输出值，只有一个确定的目标，需要利用合适的模型，使其分析数据集的相关维度信息，达到目标效果，例如聚类、子空间估计、表征学习、生成对抗网络等。</p>
</li>
<li><p>5.一般我们用都是拿数据到特定环境下训练的离线学习模式，即不会在训练时与正在变化的环境做对比交互，生成对抗网络虽然也有对比，但对比的对象是确定的不变的。与环境交互时，会观察环境中的++动作++做出应对策略，用赏对罚错的形式来提升这个智能体的“智力”。</p>
</li>
</ul>
<h2 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h2><p>了解基本的机器学习流程及方法领域</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zh.gluon.ai/">动手学习深度学习</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/83.html">关于nginx的几点小事</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2017-05-23</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/nginx/">nginx</a></span><div class="content"><p>##平滑升级nginx<br>在之前的文章说明了<a target="_blank" rel="noopener" href="https://www.yangrunwei.com/a/34.html">重新编译nginx</a>，里面就涉及到平滑升级的问题，及不停服地更新nginx版本或者给nginx编译进新的模块。nginx提供了一种方法，即给nginx当前进程发送一个USR2信号量，启用一个新的nignx（新版本或新编译的nginx），新的请求将流入nginx新进程，而旧的nignx会继续处理之前的请求，直到请求结束，旧进程退出，新进程完全接替nignx的工作。命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -USR2 `cat /run/nginx.pid`</span><br></pre></td></tr></table></figure>
<p>然而，很多人应该会得到一个结果：完全没有效果！！！<br>为什么呢？查nginx&#x2F;error.log日志会发现，抛出了这样的错误：<br>10690#0: execve() failed while executing new binary process “nginx” (2: No such file or directory)<br>这告诉我们，找不到nginx这个命令。这是因为我们一开始启动时就是依赖的是环境变量，但这时候nginx需要的是一个绝对的路径来找到nginx命令所在，所以出错了。<br>解决方法是：启动时要使用绝对路径。如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/nginx -c /etc/nginx.conf</span><br></pre></td></tr></table></figure>
<p>以后就可以顺利用USR2来平滑升级nginx了。</p>
<p>##访问限制<br>可以通过nginx提供的ngx_http_limit_conn_module模块来实现访问限制。<br>先从实例入手吧。如果想限制<a href="http://www.yangrunwei.com这个域名每个ip同时只能有一个请求，可以这样：">www.yangrunwei.com这个域名每个ip同时只能有一个请求，可以这样：</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">limit_conn_zone $binary_remote_addr zone=addr:10m;</span><br><span class="line">server &#123;</span><br><span class="line">    location /www.yangrunwei.com/ &#123;</span><br><span class="line">        limit_conn addr 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>limit_conn_zone用来指定一个存储请求的区域，请求的索引可以是ip或者server_name，语法为：limit_conn_zone $variable zone&#x3D;name:size; 这里使用$binary_remote_addr，即请求ip的二进制，大小为10m，可以同时容纳16多万请求。<br>limit_conn：指定每个给定键值的最大同时连接数，当超过这个数字时被返回503 (Service Temporarily Unavailable)错误。</p>
<p>##生成请求唯一标识<br>某些api服务，需要清晰展示请求从进入到返回的整个流程。如果以nginx作为入口的话，可以在nginx上对每个请求生成一个唯一标识，然后逐级传下去，在各级日志中打印这个标识，即可以在日志中查看到某个请求整个流程的情况。<br>生成方法：<br>####perl方式<br>这种方式较为简单，使用的是nginx的perl模块：ngx_http_perl_module，配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">perl_set $request_id &#x27;sub &#123;</span><br><span class="line">      return join &quot;&quot;, map&#123;(a..z,A..Z,0..9)[rand 62]&#125; 0..11;</span><br><span class="line">&#125;&#x27;;</span><br></pre></td></tr></table></figure>
<p>其中$request_id即为单次请求的唯一标识。若要调整标识位数为6，即将最后的0..11换为0..6</p>
<p>####其它模块<br><a target="_blank" rel="noopener" href="https://github.com/newobj/nginx-x-rid-header">nginx-x-rid-header</a><br><a target="_blank" rel="noopener" href="https://github.com/hhru/nginx_requestid">nginx_requestid</a></p>
<p>##动态加载模块<br>在nginx1.9之前，模块与nginx一起编译到二进制文件中，使用时加载所有模块运行的。<br>1.9及之后版本，nginx支持动态模块加载，即编译nginx时可使用*_module&#x3D;dynamic的形式，让模块作为动态加载使用。<br>使用动态模块时，需使用load_module path&#x2F;to&#x2F;module，加载模块。</p>
<p>##关于upstream长连接设置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">upstream api-open&#123;</span><br><span class="line">    server 127.0.0.1:3000 max_fails=0;</span><br><span class="line">    keepalive 200;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于upstream长连接配置，一般会有这样的误区，认为keepalive表示最大的长连接数，或者最小的长连接数。<br>其实都是错误的。<br>nginx默认是开启长连接的，即每个请求都会分配长连接，这里也不得不提另外一个参数，即允许多少个请求复用同一个长连接，因为这可以减少长连接数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keepalive_requests 100;</span><br></pre></td></tr></table></figure>
<p>然而，upstream里的keepalive并不是限定长连接数的最大或者最小值。而是表示当前活跃的长连接数的限定值。<br>比如，当前有1000的请求进来，nginx需要开启1000个长连接（假如keepalive_requests为0），处理完1000个请求后，由于keepalive为200，所以另外800个长连接会释放掉，当第二次1000个请求进来时，再重新建立800个长连接。<br>所以当并发高时，这个值就设置大的数值，防止长连接不断释放与建立。</p>
<p>##参考<br><a target="_blank" rel="noopener" href="http://www.ttlsa.com/nginx/nginx-limited-connection-number-ngx_http_limit_conn_module-module/">nginx限制连接数ngx_http_limit_conn_module模块</a><br><a target="_blank" rel="noopener" href="https://skyao.gitbooks.io/leaning-nginx/content/documentation/keep_alive.html">支持keep alive长连接</a><br><a target="_blank" rel="noopener" href="http://tshare365.com/archives/2420.html">Nginx总算支持动态模块了</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/82.html">关于群体心理学的一些认识</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2017-04-23</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/life/">life</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/read/">read</a></span><div class="content"><p>如果你想尝试在短时间内挑战自己的三观，那读古斯塔夫·勒庞的《乌合之从：大众心理研究》应该可以满足这样的需求。<br>##群体心理的理解<br>确实，在读这本书之前，我一直以为现今的社会是比旧社会进步很多，人类的智力也达到了空前的高点，知识和理性也高于旧时代，社会主义、民主、自由等思想是比旧社会观念高明得多。然而，对勒庞来说，这无疑是谬论。还有诸如群策群力、三个臭皮匠顶个诸葛亮的群众优于个人的观念，在作者看来，也是多么的荒唐。<br>现实中，往往是少数服从多数，因为大家更愿意相信大多数人决策出来的观点。举个生活中的小事例，比如你在购物时，往往会倾向于评价高的商品，而放弃那些无人问津的。在平时看来，这算是种从众心理吧，但明知道是这样，所有人都会有这样的想法。在这其中，你就是购物群体的一员，你所做的决定，无非就是参照他人的决定结果，然而他人及更前面的人，也可能不过是受了一些暗示性的广告效应，然后就经由重复性及传染性的加强，导致了这样一个购物事件的发生。而当我们不看评价评论，独自思考时，往往会做出理智的选择。其实这就是群体心理的体现，也是该书讲述的核心观点。群体智力往往比个体低下，煽动群体往往只需要一些暗示的词语，再加上重复性地加强，然后其再自动向群体内传染性地传播，就会形成短时间的流行，如果有时间上的积累，那就会成为根深蒂固的观念。<br>群体还有极端的特性，要么极度残暴，要么十分宽容。这也是为什么变革时往往是血流成河，甚至出现毫无人性的屠杀；待到平静时便进行关怀备至的扶贫关爱等。虽然作者提出这样的观点可能与其生活的环境（法国大革命时代）有关，然而以历史上的种种事迹为据，还是相对客观的。但是我一开始看到还是觉得心惊肉跳。若你看过《三体》里程心的遭遇，你就会深深体会到群体的那种善变与极端的特性。<br>##信仰在推动历史的车轮<br>书中提到了一个鲜明的观点，社会的进步并不是人类理性的功劳，而完全是由感情及信仰等感性因素带来的。纵观人类文明历史，在重大转折点上，理性往往没能体现，但各式各样的情感、信仰却是其动力的源泉。奴隶社会有对奴隶主的绝对服从的信念，封建社会有对君主至高权力的臣服，西方宗教社会有对宗教神权的全心奉献，近代有对民主自由的狂热与执着，乃至未来的未来，肯定会有更多更多的信仰摆在文明道路的分叉口上，那时候也只会像历史上无数次先例那样重演，只不过是名称换了，外衣变了，仅此而已。群体的力量是如此巨大，以至于所有的史书也不过是在讲述一些群体的故事而已。这就是群体社会，这就是群体心理，如果没有信仰这般遥远或者神秘的目标及希望，历史的车轮又怎会滚动下去呢？<br>##怎样在群体生活<br>其实作者并没有明确地告诉读者怎样很好地生活在群体中，相反，他告诉读者，我们是摆脱不了群体心理的影响的，因为人就是群体的一员，一个人生活能不与别人交流，那他不是神仙就是妖魔鬼怪。然而在讨论教育方面，作者提到教育应该是注重培养人的判断力和主观能动性，而不是一味去相信书本，照搬书里的内容，甚至死记硬背去应付考试来达到获取证书、文凭，这样的教育，对人和社会都是有百害无一利的。群体往往会受到各种各样心怀不轨的煽动，一旦被有心人利用，将是一场灾难；若是这股力量用在推动文明的发展，那将会是十分幸运的。对于个体生活在这样的环境，就必须具备上面说到的判断能力和主观能动性，那将是个体防御群体心理的唯一屏障。<br>##最后再说说<br>看到作者讲述群体无知对于社会的危害时，突然想到老子的小国寡民的思想，那时候看到这样的观点，是不以为然的，现在想来，还是有合理之处的。然而，社会环境在变化，人心也在转变，真理可能一直会走在路上，并不是哪个时代就能抓住她的，就如《道德经》开篇里的“道可道，非常道；明可明，非常明”。…好吧，我其实真正想说的是，现实可能并不是该书所说的那般“无情残酷”，就算不幸被他言中了，那我们面对这些未知危险，前路漫漫，更应该积极乐观地走下去。<br>#####谨以此纪念2017世界读书日，晚安。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/81.html">memcached内存结构浅析</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2017-03-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/memcached/">memcached</a></span><div class="content"><p>memcached作为缓存服务器，被广泛使用。而数据到底是如何存储在memcached的呢？下图有一个较全面的说明。<br><img src="https://img.yangrunwei.com/article-img/20170304/a18cc5f2-b855-4563-860f-3b293a04983e--m.jpg" alt="memcached内存分配" title="memcached内存分配"></p>
<p>接下来我就对memcached的使用经验和从网上学习来的知识进行下总结，也能大概说明上图内容。<br>##mem的内存分配原理<br>mem的内存分配原理包含三种结构：page, slab, chunk。<br>page是mem申请内存的最小单位，默认是1M，在启动时根据-I参数来设置，所以mem默认不支持存储超过1M的内容；<br>每个page会等分若干个chunk，每个chunk存一个key的内容；<br>相同的chunk组成一个slab。<br>至此对mem的内存分配原理应该有些了解了。<br>##监控mem<br>接下来介绍一下如何监控mem。</p>
<h3 id="stats"><a href="#stats" class="headerlink" title="stats"></a>stats</h3><p>平时可以利用telnet连接到mem，然后运行stats来获取到一些基本运行状态，比如存储键值量，命中量，get次数及set次数等。具体如下：</p>
<ol>
<li>pid: memcached服务进程的进程ID</li>
<li>uptime: memcached服务从启动到当前所经过的时间，单位是秒。</li>
<li>time: memcached服务器所在主机当前系统的时间，单位是秒。</li>
<li>version: memcached组件的版本。这里是我当前使用的1.2.6。</li>
<li>pointer_size：服务器所在主机操作系统的指针大小，一般为32或64.</li>
<li>curr_items：表示当前缓存中存放的所有缓存对象的数量。不包括目前已经从缓存中删除的对象。</li>
<li>total_items：表示从memcached服务启动到当前时间，系统存储过的所有对象的数量，包括目前已经从缓存中删除的对象。</li>
<li>bytes：表示系统存储缓存对象所使用的存储空间，单位为字节。</li>
<li>curr_connections：表示当前系统打开的连接数。</li>
<li>total_connections：表示从memcached服务启动到当前时间，系统打开过的连接的总数。</li>
<li>connection_structures：表示从memcached服务启动到当前时间，被服务器分配的连接结构的数量，这个解释是协议文档给的，具体什么意思，我目前还没搞明白。</li>
<li>cmd_get：累积获取数据的数量，这里是3，因为我测试过3次，第一次因为没有序列化对象，所以获取数据失败，是null，后边有2次是我用不同对象测试了2次。</li>
<li>cmd_set：累积保存数据的树立数量，这里是2.虽然我存储了3次，但是第一次因为没有序列化，所以没有保存到缓存，也就没有记录。</li>
<li>get_hits：表示获取数据成功的次数。</li>
<li>get_misses：表示获取数据失败的次数。</li>
<li>evictions：为了给新的数据项目释放空间，从缓存移除的缓存对象的数目。比如超过缓存大小时根据LRU算法移除的对象，以及过期的对象。</li>
<li>bytes_read：memcached服务器从网络读取的总的字节数。</li>
<li>bytes_written：memcached服务器发送到网络的总的字节数。</li>
<li>limit_maxbytes：memcached服务缓存允许使用的最大字节数。这里为67108864字节，也就是是64M.与我们启动memcached服务设置的大小一致。</li>
<li>threads：被请求的工作线程的总数量</li>
</ol>
<p>###stats slabs<br>stats slabs可以用来查看slab情况，包括数量和其下chunk的使用情况，还可以查看到mem当前申请的总内存量。</p>
<p>###memcache-top<br><a target="_blank" rel="noopener" href="https://code.google.com/archive/p/memcache-top/">memcache-top</a>是一个mem监控工具，可支持对多个mem运行时的各项指标进行监控，轻量方便。</p>
<p>##evictions&gt;0<br>我们接下来谈谈使用时mem数据被踢除(即evictions&gt;0)的情况。<br>我们已经知道chunk是存储内容的最小单位，一个slab下的所有chunk大小都是一样的。当我们存储的内容大小各样时，mem必定会分配出许多slab，若考虑到极端情况，每个内容只放在一个slab里，那是十分浪费内存的，因为申请到的内存大部分空着。所以有时候我们会在监控(memcache-top)里看到，mem的USAGE很小，但却出现了evictions&gt;0，通过查看mem的内存申请量可以看到已经到达设定的最大分配内存。解决这种问题，无非是加大设定的内存量，或者是减小存入mem的内容大小类别，提高内存利用率。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a target="_blank" rel="noopener" href="http://san-yun.iteye.com/blog/1591803">memcached 内存分配(slab和chunk)</a><br><a target="_blank" rel="noopener" href="http://andto.iteye.com/blog/1560906">通过stats命令分析Memcached的内部状态</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/80.html">如何在linux创建及删除软链</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-12-28</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/linux/">linux</a></span><div class="content"><p>##创建软链<br>linux的ln命令可以为我们创建一个文件或目录的链接，有两种链接，一种是软链，像windows下的快捷方式，一种是硬链，则像是副本。<br>命令格式：<br>ln [参数][源文件或目录][目标文件或目录]<br>如：创建一个目录软链</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /test ~/test</span><br></pre></td></tr></table></figure>
<p>将根目录的test目录软链到当前用户目录的test目录</p>
<h2 id="删除软链"><a href="#删除软链" class="headerlink" title="删除软链"></a>删除软链</h2><p>如果想要删除这个目录软链，则直接rm，但需要注意的是，不要在目录后面加‘&#x2F;’，这样系统会尝试删除实际目录下的文件，并不是删除软链。<br>如删除上述软链目录：<br>错误方式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm ~/test/</span><br></pre></td></tr></table></figure>

<p>正确方式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm ~/test</span><br></pre></td></tr></table></figure>

<p>删除文件软链也是直接rm</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/79.html">git 反转提交</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-12-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/git/">git</a></span><div class="content"><p>有时我们需要让仓库回退上前面的某个版本，相当于撤消一些版本修改，该如何操作呢？</p>
<h2 id="git-reset-版本回退"><a href="#git-reset-版本回退" class="headerlink" title="git reset 版本回退"></a>git reset 版本回退</h2><p>往往我们会想到reset的方式来回退版本。<br>具体方法是:<br>1.获取commit log id</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure>
<p>2.回退到指定commit</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset commitLogId</span><br></pre></td></tr></table></figure>
<p>reset还有一些注意点，可以参考<a target="_blank" rel="noopener" href="https://www.yangrunwei.com/a/77.html">git基本架构</a>这篇介绍</p>
<p>但这种方式会删除一些版本历史，在分支的合并或不同开发者对此分支的push提交会可能会造成比较多的冲突。因为其他开发者可能在一个较晚的commit基础上修改代码并提交，这时当仓库被reset到一个较早的版本，很有可能就会与这次提交的代码有冲突。</p>
<h2 id="git-revert-反转提交"><a href="#git-revert-反转提交" class="headerlink" title="git revert 反转提交"></a>git revert 反转提交</h2><p>如果你想让进行版本回退，但又不想删除版本历史避免代码冲突，可以使用反转提交的方式。<br>反转提交的操作方法跟reset很类似，先是获取到commit log id，然后</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git revert commitLogId</span><br></pre></td></tr></table></figure>
<p>这种方式会让仓库的版本历史看起来就像正常工作时的代码提交，因为反转提交会创建一个新提交来达到版本回退的效果，所以版本历史会是一直向前的。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/78.html">git 切换到远程分支</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-12-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/git/">git</a></span><div class="content"><p>在实践开发中，git往往会有多个分支，有时候我们想将远程的某个分支拉下来作为一个本地分支，该如何操作呢？</p>
<p>下面演示下如何将远程dev分支拉到本地，并创建一个同名分支。<br>#####1.查看远程有哪些分支</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -va</span><br></pre></td></tr></table></figure>
<p>例如结果如下：</p>
<ul>
<li>master<br>remotes&#x2F;origin&#x2F;dev<br>remotes&#x2F;origin&#x2F;glowry</li>
</ul>
<p>#####2.拉取远程分支并创建本地分支</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch dev remotes/origin/dev</span><br></pre></td></tr></table></figure>

<p>#####3.查看本地分支</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure>
<p>结果如下：<br>*master<br>dev</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/77.html">Git基本架构</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-12-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/git/">git</a></span><div class="content"><p>Git基本架构，如图：<br><img src="https://img.yangrunwei.com/article-img/20161215/f7f71965-d597-4d14-a579-3d2dfe2b8655--git%E6%9E%B6%E6%9E%84.png" alt="git架构" title="git架构"></p>
<p>大致可分为几个部分，分别是git目录、工作目录、暂存区、本地仓库、远程仓库，所有这些便组成了git的一个分支，当然有些可以是可选的，比如本地分支就没有远程仓库。<br>了解git的组成，可以让我们更能hold住开发时对代码的管理。比如切换分支时可对当前分支的修改放在stash，不用提交到本地仓库去；当前同时实现多个需求，可分别提交，方便版本迭代或者bug紧急处理；提交出错可回滚到适当位置，并可控制对当前修改的影响等等。<br>通过熟悉git架构，让代码开发更加愉快。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="http://gitbook.liuhui998.com/index.html">git book</a><br><a target="_blank" rel="noopener" href="https://github.com/xirong/my-git/blob/master/useful-git-command.md">useful git command</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/a/76.html">MNIST机器学习入门</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2016-10-16</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/tech/">tech</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/ml/">ml</a></span><div class="content"><p>这段时间一直在了解机器学习方面的知识，因为涉及高等数学（主要是微积分）、概率论、统计学、线性代数等数学知识，不得不回归到大学的课本上，这是一个周期很长的学习过程。经过这段时间的沉淀，总算能看懂一些机器学习方面的理论知识，便在<a target="_blank" rel="noopener" href="http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html">极客学院的机器学习教程</a>进行机器学习方面的研究，主要是利用tensorflow这个工具来开发机器学习的应用。下面是我对入门教程的一些源码，算是做个笔记，也可以分享给和我一样正在入门的小伙伴。<br>这是根据教程写下来的代码，其中还包括了模型的保存，方便接下来做模型的实际应用。</p>
<h5 id="minist-py"><a href="#minist-py" class="headerlink" title="minist.py"></a>minist.py</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</span><br><span class="line">print(&quot;Download Done!&quot;)</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784])</span><br><span class="line"></span><br><span class="line"># paras</span><br><span class="line">W = tf.Variable(tf.zeros([784, 10]))</span><br><span class="line">b = tf.Variable(tf.zeros([10]))</span><br><span class="line"></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</span><br><span class="line">y_ = tf.placeholder(tf.float32, [None, 10])</span><br><span class="line"></span><br><span class="line"># loss func</span><br><span class="line">cross_entropy = -tf.reduce_sum(y_ * tf.log(y))</span><br><span class="line"></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"># init</span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"># train</span><br><span class="line">for i in range(1000):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(100)</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">correct_prediction = tf.equal(tf.arg_max(y, 1), tf.arg_max(y_, 1))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</span><br><span class="line"></span><br><span class="line">print(&quot;Accuarcy on Test-dataset: &quot;, sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line"># save model </span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">save_path = saver.save(sess, &quot;./model/minist_softmax.ckpt&quot;)</span><br><span class="line">print(&quot;Model saved in file: &quot;, save_path)</span><br></pre></td></tr></table></figure>
<p>运行上述代码便可得到模型。由于需要下载数据集，所以第一次运行会比较慢，需要耐心等待。</p>
<p>下面是应用模型对实际手写数字图片做识别的源码。你需要用ps做一些黑底白字的手写数字图片资源。</p>
<h5 id="test-minist-py"><a href="#test-minist-py" class="headerlink" title="test_minist.py"></a>test_minist.py</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: UTF-8 -*-  </span><br><span class="line">from PIL import Image</span><br><span class="line">from numpy import *</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">if len(sys.argv) &lt; 2 :</span><br><span class="line">	print(&#x27;argv must at least 2. you give &#x27;+str(len(sys.argv)))</span><br><span class="line">	sys.exit()</span><br><span class="line">filename = sys.argv[1]</span><br><span class="line">im=Image.open(filename)</span><br><span class="line">img = array(im.resize((28, 28), Image.ANTIALIAS).convert(&quot;L&quot;))</span><br><span class="line"># data = transpose(img.ravel())</span><br><span class="line">data = img.reshape([1, 784])</span><br><span class="line"># print(data)</span><br><span class="line"></span><br><span class="line"># xData = tf.Variable(data, name=&quot;x&quot;)</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784])</span><br><span class="line">W = tf.Variable(tf.zeros([784, 10]))</span><br><span class="line">b = tf.Variable(tf.zeros([10]))</span><br><span class="line"></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</span><br><span class="line"># y = tf.add(b, tf.matmul(x, W))</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">init_op = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">	sess.run(init_op)</span><br><span class="line">	save_path = &quot;./model/minist_softmax.ckpt&quot;</span><br><span class="line">	saver.restore(sess, save_path)</span><br><span class="line">	# print(&quot;Model restored.&quot;)</span><br><span class="line">	predictions = sess.run(y, feed_dict=&#123;x: data&#125;)</span><br><span class="line">	print(predictions[0]);</span><br><span class="line">	# print(tf.arg_max(predictions[0], 1))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>注：上述代码需要两个python库，Pillow和numpy，执行如下命令来安装。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Pillow numpy</span><br></pre></td></tr></table></figure>
<p>接下来可以通过命令指定需要测试的图片，如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python test_minist.py ./img/test_1.jpg</span><br></pre></td></tr></table></figure>
<p>结果是一个数组，值为1的索引就代表识别出来的数字了。</p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2015 - 2022 By 杨润炜</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>